{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Urban sounds using Deep Learning\n",
    "\n",
    "## 3 Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "# %store -r x_train \n",
    "# %store -r x_test \n",
    "# %store -r y_train \n",
    "# %store -r y_test \n",
    "# %store -r yy \n",
    "# %store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data,x):\n",
    "    noise = np.random.randn(len(data))\n",
    "    data_noise = data + x * noise\n",
    "    return data_noise\n",
    "\n",
    "def shift(data,x):\n",
    "    return np.roll(data, x)\n",
    "\n",
    "def stretch(data, rate):\n",
    "    data = librosa.effects.time_stretch(data, rate)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "X_=[]\n",
    "y_=[]\n",
    "dir_= './clinical/converted_seg/cneg/'\n",
    "p='negative'\n",
    "for soundDir in (os.listdir(dir_)):\n",
    "    data_x, sampling_rate = librosa.load(dir_+soundDir,res_type='kaiser_fast')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs)\n",
    "    y_.append('negative')\n",
    "\n",
    "    data_noise = add_noise(data_x,0.005)\n",
    "    mfccs_noise = np.mean(librosa.feature.mfcc(y=data_noise, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_noise)\n",
    "    y_.append(p)\n",
    "\n",
    "    data_shift = shift(data_x,1600)\n",
    "    mfccs_shift = np.mean(librosa.feature.mfcc(y=data_shift, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_shift)\n",
    "    y_.append(p)\n",
    "\n",
    "    data_stretch = stretch(data_x,1.2)\n",
    "    mfccs_stretch = np.mean(librosa.feature.mfcc(y=data_stretch, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_stretch)\n",
    "    y_.append(p)\n",
    "\n",
    "    data_stretch_2 = stretch(data_x,0.8)\n",
    "    mfccs_stretch_2 = np.mean(librosa.feature.mfcc(y=data_stretch_2, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_stretch_2)\n",
    "    y_.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "dir_= './clinical/converted_seg/cpos/'\n",
    "p='positive'\n",
    "for soundDir in (os.listdir(dir_)):\n",
    "    data_x, sampling_rate = librosa.load(dir_+soundDir,res_type='kaiser_fast')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs)\n",
    "    y_.append('positive')\n",
    "\n",
    "    data_noise = add_noise(data_x,0.005)\n",
    "    mfccs_noise = np.mean(librosa.feature.mfcc(y=data_noise, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_noise)\n",
    "    y_.append(p)\n",
    "\n",
    "    data_shift = shift(data_x,1600)\n",
    "    mfccs_shift = np.mean(librosa.feature.mfcc(y=data_shift, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_shift)\n",
    "    y_.append(p)\n",
    "\n",
    "    data_stretch = stretch(data_x,1.2)\n",
    "    mfccs_stretch = np.mean(librosa.feature.mfcc(y=data_stretch, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_stretch)\n",
    "    y_.append(p)\n",
    "\n",
    "    data_stretch_2 = stretch(data_x,0.8)\n",
    "    mfccs_stretch_2 = np.mean(librosa.feature.mfcc(y=data_stretch_2, sr=sampling_rate, n_mfcc=40).T,axis=0) \n",
    "    X_.append(mfccs_stretch_2)\n",
    "    y_.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_)\n",
    "y = np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.10094818e+02  3.20862427e+01 -1.48833714e+01 ...  3.81080687e-01\n",
      "   3.74728590e-01  1.38507652e+00]\n",
      " [-2.69644516e+02  1.59614408e+01 -4.85760469e+00 ...  8.94178798e-01\n",
      "   4.90179794e-01  1.64928549e+00]\n",
      " [-5.08641235e+02  3.45660172e+01 -1.65387192e+01 ...  3.78286183e-01\n",
      "   2.82604098e-01  1.48085976e+00]\n",
      " ...\n",
      " [-3.49824341e+02  5.46507072e+01 -4.65615921e+01 ... -8.15696359e-01\n",
      "  -1.11679304e+00 -2.90427953e-01]\n",
      " [-3.64710724e+02  5.27145729e+01 -4.16428795e+01 ... -1.20872974e+00\n",
      "  -1.72089839e+00 -1.17781043e+00]\n",
      " [-3.71380310e+02  5.08207207e+01 -4.21386871e+01 ... -1.21099401e+00\n",
      "  -1.07187545e+00 -2.70886362e-01]]\n",
      "['negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "# X = np.array(featuresdf.feature.tolist())\n",
    "# y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "print(yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model architecture - MLP\n",
    "\n",
    "We will start with constructing a Multilayer Perceptron (MLP) Neural Network using Keras and a Tensorflow backend. \n",
    "\n",
    "Starting with a `sequential` model so we can build the model layer by layer. \n",
    "\n",
    "We will begin with a simple model architecture, consisting of three layers, an input layer, a hidden layer and an output layer. All three layers will be of the `dense` layer type which is a standard layer type that is used in many cases for neural networks. \n",
    "\n",
    "The first layer will receive the input shape. As each sample contains 40 MFCCs (or columns) we have a shape of (1x40) this means we will start with an input shape of 40. \n",
    "\n",
    "The first two layers will have 256 nodes. The activation function we will be using for our first 2 layers is the `ReLU`, or `Rectified Linear Activation`. This activation function has been proven to work well in neural networks.\n",
    "\n",
    "We will also apply a `Dropout` value of 50% on our first two layers. This will randomly exclude nodes from each update cycle which in turn results in a network that is capable of better generalisation and is less likely to overfit the training data.\n",
    "\n",
    "Our output layer will have 2 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is `softmax`. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(yy.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the following three parameters: \n",
    "\n",
    "* Loss function - we will use `categorical_crossentropy`. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
    "\n",
    "* Metrics - we will use the `accuracy` metric which will allow us to view the accuracy score on the validation data when we train the model. \n",
    "\n",
    "* Optimizer - here we will use `adam` which is a generally good optimizer for many use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               10496     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,778\n",
      "Trainable params: 51,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 67.0330%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. \n",
    "\n",
    "We will start with 100 epochs which is the number of times the model will cycle through the data. The model will improve on each cycle until it reaches a certain point. \n",
    "\n",
    "We will also start with a low batch size, as having a large batch size can reduce the generalisation ability of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      " 1/14 [=>............................] - ETA: 6s - loss: 13.9904 - accuracy: 0.5000\n",
      "Epoch 00001: val_loss improved from inf to 3.63762, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 1s 8ms/step - loss: 12.0757 - accuracy: 0.5603 - val_loss: 3.6376 - val_accuracy: 0.6703\n",
      "Epoch 2/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 4.5776 - accuracy: 0.6250\n",
      "Epoch 00002: val_loss improved from 3.63762 to 0.56254, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.0992 - accuracy: 0.5177 - val_loss: 0.5625 - val_accuracy: 0.7418\n",
      "Epoch 3/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 5.1863 - accuracy: 0.4062\n",
      "Epoch 00003: val_loss did not improve from 0.56254\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.6387 - accuracy: 0.4941 - val_loss: 0.6084 - val_accuracy: 0.7033\n",
      "Epoch 4/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 3.1871 - accuracy: 0.5625\n",
      "Epoch 00004: val_loss improved from 0.56254 to 0.49846, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.0053 - accuracy: 0.5508 - val_loss: 0.4985 - val_accuracy: 0.8022\n",
      "Epoch 5/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.7145 - accuracy: 0.5625\n",
      "Epoch 00005: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.2838 - accuracy: 0.5225 - val_loss: 0.5206 - val_accuracy: 0.8132\n",
      "Epoch 6/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 2.0030 - accuracy: 0.5312\n",
      "Epoch 00006: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.8382 - accuracy: 0.4965 - val_loss: 0.7023 - val_accuracy: 0.4176\n",
      "Epoch 7/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.9967 - accuracy: 0.6562\n",
      "Epoch 00007: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.4729 - accuracy: 0.5532 - val_loss: 0.8779 - val_accuracy: 0.3352\n",
      "Epoch 8/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.6752 - accuracy: 0.4375\n",
      "Epoch 00008: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.2422 - accuracy: 0.5674 - val_loss: 0.7806 - val_accuracy: 0.3516\n",
      "Epoch 9/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.2415 - accuracy: 0.6250\n",
      "Epoch 00009: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1070 - accuracy: 0.5579 - val_loss: 0.7074 - val_accuracy: 0.4341\n",
      "Epoch 10/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.0336 - accuracy: 0.5312\n",
      "Epoch 00010: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0577 - accuracy: 0.5603 - val_loss: 0.8231 - val_accuracy: 0.3516\n",
      "Epoch 11/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8288 - accuracy: 0.5938\n",
      "Epoch 00011: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1377 - accuracy: 0.5106 - val_loss: 0.7837 - val_accuracy: 0.3407\n",
      "Epoch 12/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.1800 - accuracy: 0.4688\n",
      "Epoch 00012: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.9703 - accuracy: 0.5414 - val_loss: 0.6575 - val_accuracy: 0.7747\n",
      "Epoch 13/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 1.3068 - accuracy: 0.5000\n",
      "Epoch 00013: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8882 - accuracy: 0.5674 - val_loss: 0.6674 - val_accuracy: 0.7802\n",
      "Epoch 14/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8900 - accuracy: 0.5312\n",
      "Epoch 00014: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.8893 - accuracy: 0.5343 - val_loss: 0.7122 - val_accuracy: 0.3352\n",
      "Epoch 15/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7456 - accuracy: 0.5312\n",
      "Epoch 00015: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.8890 - accuracy: 0.5390 - val_loss: 0.6698 - val_accuracy: 0.7308\n",
      "Epoch 16/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.9201 - accuracy: 0.5312\n",
      "Epoch 00016: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7784 - accuracy: 0.5745 - val_loss: 0.6479 - val_accuracy: 0.7967\n",
      "Epoch 17/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7748 - accuracy: 0.5000\n",
      "Epoch 00017: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7935 - accuracy: 0.5556 - val_loss: 0.6817 - val_accuracy: 0.4725\n",
      "Epoch 18/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8403 - accuracy: 0.5312\n",
      "Epoch 00018: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7734 - accuracy: 0.5626 - val_loss: 0.6982 - val_accuracy: 0.3462\n",
      "Epoch 19/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7872 - accuracy: 0.4375\n",
      "Epoch 00019: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.5532 - val_loss: 0.6819 - val_accuracy: 0.6209\n",
      "Epoch 20/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7084 - accuracy: 0.5938\n",
      "Epoch 00020: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7466 - accuracy: 0.5721 - val_loss: 0.6744 - val_accuracy: 0.7088\n",
      "Epoch 21/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7443 - accuracy: 0.5000\n",
      "Epoch 00021: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7236 - accuracy: 0.5957 - val_loss: 0.6879 - val_accuracy: 0.6868\n",
      "Epoch 22/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8504 - accuracy: 0.4375\n",
      "Epoch 00022: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7294 - accuracy: 0.5721 - val_loss: 0.6996 - val_accuracy: 0.3571\n",
      "Epoch 23/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6838 - accuracy: 0.6562\n",
      "Epoch 00023: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7539 - accuracy: 0.5674 - val_loss: 0.6528 - val_accuracy: 0.8132\n",
      "Epoch 24/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7261 - accuracy: 0.5312\n",
      "Epoch 00024: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6028 - val_loss: 0.6765 - val_accuracy: 0.6099\n",
      "Epoch 25/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7069 - accuracy: 0.6562\n",
      "Epoch 00025: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7670 - accuracy: 0.5603 - val_loss: 0.6929 - val_accuracy: 0.4505\n",
      "Epoch 26/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8117 - accuracy: 0.4688\n",
      "Epoch 00026: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.5603 - val_loss: 0.6957 - val_accuracy: 0.4121\n",
      "Epoch 27/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7514 - accuracy: 0.7500\n",
      "Epoch 00027: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.5816 - val_loss: 0.6902 - val_accuracy: 0.6429\n",
      "Epoch 28/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6258 - accuracy: 0.6562\n",
      "Epoch 00028: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5603 - val_loss: 0.6974 - val_accuracy: 0.3626\n",
      "Epoch 29/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5889 - accuracy: 0.7812\n",
      "Epoch 00029: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5768 - val_loss: 0.6830 - val_accuracy: 0.6484\n",
      "Epoch 30/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6153 - accuracy: 0.6875\n",
      "Epoch 00030: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6618 - accuracy: 0.6194 - val_loss: 0.6366 - val_accuracy: 0.8187\n",
      "Epoch 31/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7352 - accuracy: 0.5000\n",
      "Epoch 00031: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.5910 - val_loss: 0.6630 - val_accuracy: 0.6813\n",
      "Epoch 32/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7150 - accuracy: 0.5312\n",
      "Epoch 00032: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6005 - val_loss: 0.6198 - val_accuracy: 0.8077\n",
      "Epoch 33/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.8199 - accuracy: 0.5312\n",
      "Epoch 00033: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7214 - accuracy: 0.6028 - val_loss: 0.6017 - val_accuracy: 0.8187\n",
      "Epoch 34/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5463 - accuracy: 0.6875\n",
      "Epoch 00034: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.5887 - val_loss: 0.5281 - val_accuracy: 0.8077\n",
      "Epoch 35/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7021 - accuracy: 0.4688\n",
      "Epoch 00035: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.5863 - val_loss: 0.6254 - val_accuracy: 0.8132\n",
      "Epoch 36/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6568 - accuracy: 0.6875\n",
      "Epoch 00036: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6099 - val_loss: 0.5875 - val_accuracy: 0.8297\n",
      "Epoch 37/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7147 - accuracy: 0.5312\n",
      "Epoch 00037: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6147 - val_loss: 0.5558 - val_accuracy: 0.8297\n",
      "Epoch 38/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6182 - accuracy: 0.6250\n",
      "Epoch 00038: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.6147 - val_loss: 0.5778 - val_accuracy: 0.8242\n",
      "Epoch 39/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5756 - accuracy: 0.5625\n",
      "Epoch 00039: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6525 - val_loss: 0.6013 - val_accuracy: 0.8022\n",
      "Epoch 40/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6975 - accuracy: 0.4688\n",
      "Epoch 00040: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6076 - val_loss: 0.6020 - val_accuracy: 0.8022\n",
      "Epoch 41/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6908 - accuracy: 0.6562\n",
      "Epoch 00041: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6667 - val_loss: 0.5455 - val_accuracy: 0.8242\n",
      "Epoch 42/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6769 - accuracy: 0.6875\n",
      "Epoch 00042: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6407 - val_loss: 0.5285 - val_accuracy: 0.8242\n",
      "Epoch 43/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5898 - accuracy: 0.6250\n",
      "Epoch 00043: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6501 - val_loss: 0.5496 - val_accuracy: 0.8297\n",
      "Epoch 44/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6545 - accuracy: 0.6875\n",
      "Epoch 00044: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6809 - val_loss: 0.5505 - val_accuracy: 0.8187\n",
      "Epoch 45/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7179 - accuracy: 0.5938\n",
      "Epoch 00045: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6690 - val_loss: 0.5148 - val_accuracy: 0.8187\n",
      "Epoch 46/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5633 - accuracy: 0.7188\n",
      "Epoch 00046: val_loss did not improve from 0.49846\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6690 - val_loss: 0.5346 - val_accuracy: 0.8571\n",
      "Epoch 47/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5098 - accuracy: 0.8438\n",
      "Epoch 00047: val_loss improved from 0.49846 to 0.48186, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5886 - accuracy: 0.7329 - val_loss: 0.4819 - val_accuracy: 0.8187\n",
      "Epoch 48/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6212 - accuracy: 0.5938\n",
      "Epoch 00048: val_loss did not improve from 0.48186\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.6667 - val_loss: 0.5019 - val_accuracy: 0.8352\n",
      "Epoch 49/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5816 - accuracy: 0.5938\n",
      "Epoch 00049: val_loss did not improve from 0.48186\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.6785 - val_loss: 0.5076 - val_accuracy: 0.8407\n",
      "Epoch 50/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5889 - accuracy: 0.6875\n",
      "Epoch 00050: val_loss improved from 0.48186 to 0.46332, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5885 - accuracy: 0.7187 - val_loss: 0.4633 - val_accuracy: 0.8242\n",
      "Epoch 51/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5459 - accuracy: 0.7500\n",
      "Epoch 00051: val_loss did not improve from 0.46332\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7139 - val_loss: 0.4873 - val_accuracy: 0.8407\n",
      "Epoch 52/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6721 - accuracy: 0.6250\n",
      "Epoch 00052: val_loss improved from 0.46332 to 0.46032, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6738 - val_loss: 0.4603 - val_accuracy: 0.8297\n",
      "Epoch 53/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6099 - accuracy: 0.6250\n",
      "Epoch 00053: val_loss did not improve from 0.46032\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.6879 - val_loss: 0.5071 - val_accuracy: 0.8022\n",
      "Epoch 54/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6059 - accuracy: 0.5938\n",
      "Epoch 00054: val_loss improved from 0.46032 to 0.44000, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5743 - accuracy: 0.6974 - val_loss: 0.4400 - val_accuracy: 0.8352\n",
      "Epoch 55/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6732 - accuracy: 0.7188\n",
      "Epoch 00055: val_loss did not improve from 0.44000\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6832 - val_loss: 0.4633 - val_accuracy: 0.8407\n",
      "Epoch 56/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5537 - accuracy: 0.6875\n",
      "Epoch 00056: val_loss did not improve from 0.44000\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7258 - val_loss: 0.4697 - val_accuracy: 0.8407\n",
      "Epoch 57/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5061 - accuracy: 0.7500\n",
      "Epoch 00057: val_loss did not improve from 0.44000\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7234 - val_loss: 0.4588 - val_accuracy: 0.8462\n",
      "Epoch 58/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7001 - accuracy: 0.6875\n",
      "Epoch 00058: val_loss did not improve from 0.44000\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6998 - val_loss: 0.4729 - val_accuracy: 0.7912\n",
      "Epoch 59/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5571 - accuracy: 0.6875\n",
      "Epoch 00059: val_loss did not improve from 0.44000\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7541 - val_loss: 0.4507 - val_accuracy: 0.8352\n",
      "Epoch 60/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5493 - accuracy: 0.6562\n",
      "Epoch 00060: val_loss improved from 0.44000 to 0.42013, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5524 - accuracy: 0.7329 - val_loss: 0.4201 - val_accuracy: 0.8462\n",
      "Epoch 61/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4547 - accuracy: 0.7500\n",
      "Epoch 00061: val_loss did not improve from 0.42013\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7494 - val_loss: 0.4221 - val_accuracy: 0.8516\n",
      "Epoch 62/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4655 - accuracy: 0.7812\n",
      "Epoch 00062: val_loss improved from 0.42013 to 0.40564, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7683 - val_loss: 0.4056 - val_accuracy: 0.8571\n",
      "Epoch 63/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6602 - accuracy: 0.6562\n",
      "Epoch 00063: val_loss did not improve from 0.40564\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7470 - val_loss: 0.4221 - val_accuracy: 0.8516\n",
      "Epoch 64/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5909 - accuracy: 0.6562\n",
      "Epoch 00064: val_loss did not improve from 0.40564\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7305 - val_loss: 0.4117 - val_accuracy: 0.8516\n",
      "Epoch 65/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.7305 - accuracy: 0.5312\n",
      "Epoch 00065: val_loss did not improve from 0.40564\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7447 - val_loss: 0.4216 - val_accuracy: 0.8516\n",
      "Epoch 66/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5947 - accuracy: 0.7500\n",
      "Epoch 00066: val_loss did not improve from 0.40564\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7258 - val_loss: 0.4079 - val_accuracy: 0.8516\n",
      "Epoch 67/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.9035 - accuracy: 0.7812\n",
      "Epoch 00067: val_loss improved from 0.40564 to 0.37856, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7541 - val_loss: 0.3786 - val_accuracy: 0.8462\n",
      "Epoch 68/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4421 - accuracy: 0.8125\n",
      "Epoch 00068: val_loss did not improve from 0.37856\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7565 - val_loss: 0.3949 - val_accuracy: 0.8571\n",
      "Epoch 69/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5439 - accuracy: 0.7188\n",
      "Epoch 00069: val_loss did not improve from 0.37856\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7163 - val_loss: 0.3925 - val_accuracy: 0.8571\n",
      "Epoch 70/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3808 - accuracy: 0.8125\n",
      "Epoch 00070: val_loss improved from 0.37856 to 0.37478, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7612 - val_loss: 0.3748 - val_accuracy: 0.8681\n",
      "Epoch 71/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4682 - accuracy: 0.7812\n",
      "Epoch 00071: val_loss did not improve from 0.37478\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7612 - val_loss: 0.3777 - val_accuracy: 0.8681\n",
      "Epoch 72/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3788 - accuracy: 0.8125\n",
      "Epoch 00072: val_loss did not improve from 0.37478\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7541 - val_loss: 0.4220 - val_accuracy: 0.8352\n",
      "Epoch 73/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4878 - accuracy: 0.6875\n",
      "Epoch 00073: val_loss improved from 0.37478 to 0.37209, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7730 - val_loss: 0.3721 - val_accuracy: 0.8681\n",
      "Epoch 74/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4447 - accuracy: 0.7812\n",
      "Epoch 00074: val_loss improved from 0.37209 to 0.37166, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.8038 - val_loss: 0.3717 - val_accuracy: 0.8681\n",
      "Epoch 75/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8438\n",
      "Epoch 00075: val_loss improved from 0.37166 to 0.36780, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7730 - val_loss: 0.3678 - val_accuracy: 0.8571\n",
      "Epoch 76/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3523 - accuracy: 0.8438\n",
      "Epoch 00076: val_loss did not improve from 0.36780\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7801 - val_loss: 0.3884 - val_accuracy: 0.7912\n",
      "Epoch 77/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6406 - accuracy: 0.6562\n",
      "Epoch 00077: val_loss did not improve from 0.36780\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7400 - val_loss: 0.3782 - val_accuracy: 0.8571\n",
      "Epoch 78/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5492 - accuracy: 0.6562\n",
      "Epoch 00078: val_loss did not improve from 0.36780\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7660 - val_loss: 0.3730 - val_accuracy: 0.8571\n",
      "Epoch 79/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4441 - accuracy: 0.7500\n",
      "Epoch 00079: val_loss did not improve from 0.36780\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7494 - val_loss: 0.3893 - val_accuracy: 0.8516\n",
      "Epoch 80/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3985 - accuracy: 0.9062\n",
      "Epoch 00080: val_loss did not improve from 0.36780\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7754 - val_loss: 0.4060 - val_accuracy: 0.7857\n",
      "Epoch 81/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5201 - accuracy: 0.7812\n",
      "Epoch 00081: val_loss did not improve from 0.36780\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7754 - val_loss: 0.3854 - val_accuracy: 0.8022\n",
      "Epoch 82/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4168 - accuracy: 0.8438\n",
      "Epoch 00082: val_loss improved from 0.36780 to 0.33238, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7896 - val_loss: 0.3324 - val_accuracy: 0.8626\n",
      "Epoch 83/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5358 - accuracy: 0.7188\n",
      "Epoch 00083: val_loss did not improve from 0.33238\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7707 - val_loss: 0.3905 - val_accuracy: 0.7857\n",
      "Epoch 84/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5536 - accuracy: 0.7188\n",
      "Epoch 00084: val_loss did not improve from 0.33238\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8038 - val_loss: 0.3352 - val_accuracy: 0.8901\n",
      "Epoch 85/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4132 - accuracy: 0.7500\n",
      "Epoch 00085: val_loss did not improve from 0.33238\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.3692 - val_accuracy: 0.8352\n",
      "Epoch 86/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3980 - accuracy: 0.7812\n",
      "Epoch 00086: val_loss improved from 0.33238 to 0.32008, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8085 - val_loss: 0.3201 - val_accuracy: 0.8791\n",
      "Epoch 87/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5490 - accuracy: 0.7500\n",
      "Epoch 00087: val_loss improved from 0.32008 to 0.31404, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8274 - val_loss: 0.3140 - val_accuracy: 0.8791\n",
      "Epoch 88/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.9688\n",
      "Epoch 00088: val_loss improved from 0.31404 to 0.30273, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7991 - val_loss: 0.3027 - val_accuracy: 0.8846\n",
      "Epoch 89/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6206 - accuracy: 0.8125\n",
      "Epoch 00089: val_loss did not improve from 0.30273\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7896 - val_loss: 0.3451 - val_accuracy: 0.8736\n",
      "Epoch 90/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.6186 - accuracy: 0.6562\n",
      "Epoch 00090: val_loss did not improve from 0.30273\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8038 - val_loss: 0.3068 - val_accuracy: 0.8846\n",
      "Epoch 91/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4505 - accuracy: 0.8125\n",
      "Epoch 00091: val_loss did not improve from 0.30273\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7849 - val_loss: 0.3831 - val_accuracy: 0.8407\n",
      "Epoch 92/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3694 - accuracy: 0.8750\n",
      "Epoch 00092: val_loss did not improve from 0.30273\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8085 - val_loss: 0.3097 - val_accuracy: 0.8846\n",
      "Epoch 93/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3322 - accuracy: 0.8438\n",
      "Epoch 00093: val_loss did not improve from 0.30273\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8322 - val_loss: 0.3516 - val_accuracy: 0.8462\n",
      "Epoch 94/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8438\n",
      "Epoch 00094: val_loss improved from 0.30273 to 0.29333, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.7872 - val_loss: 0.2933 - val_accuracy: 0.8901\n",
      "Epoch 95/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8438\n",
      "Epoch 00095: val_loss improved from 0.29333 to 0.28682, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3535 - accuracy: 0.8203 - val_loss: 0.2868 - val_accuracy: 0.8956\n",
      "Epoch 96/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3894 - accuracy: 0.7812\n",
      "Epoch 00096: val_loss improved from 0.28682 to 0.28514, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8227 - val_loss: 0.2851 - val_accuracy: 0.8956\n",
      "Epoch 97/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2321 - accuracy: 0.9062\n",
      "Epoch 00097: val_loss improved from 0.28514 to 0.28131, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.8605 - val_loss: 0.2813 - val_accuracy: 0.8791\n",
      "Epoch 98/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4710 - accuracy: 0.7188\n",
      "Epoch 00098: val_loss improved from 0.28131 to 0.27973, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8038 - val_loss: 0.2797 - val_accuracy: 0.8901\n",
      "Epoch 99/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5082 - accuracy: 0.7812\n",
      "Epoch 00099: val_loss did not improve from 0.27973\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8298 - val_loss: 0.3045 - val_accuracy: 0.8571\n",
      "Epoch 100/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3492 - accuracy: 0.7500\n",
      "Epoch 00100: val_loss did not improve from 0.27973\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8440 - val_loss: 0.2826 - val_accuracy: 0.8791\n",
      "Epoch 101/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2204 - accuracy: 0.9375\n",
      "Epoch 00101: val_loss improved from 0.27973 to 0.27827, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3442 - accuracy: 0.8463 - val_loss: 0.2783 - val_accuracy: 0.8791\n",
      "Epoch 102/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3091 - accuracy: 0.9062\n",
      "Epoch 00102: val_loss improved from 0.27827 to 0.26860, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8511 - val_loss: 0.2686 - val_accuracy: 0.8956\n",
      "Epoch 103/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4363 - accuracy: 0.7812\n",
      "Epoch 00103: val_loss improved from 0.26860 to 0.26496, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8629 - val_loss: 0.2650 - val_accuracy: 0.8901\n",
      "Epoch 104/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3865 - accuracy: 0.8125\n",
      "Epoch 00104: val_loss improved from 0.26496 to 0.24655, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8416 - val_loss: 0.2466 - val_accuracy: 0.9231\n",
      "Epoch 105/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3634 - accuracy: 0.8750\n",
      "Epoch 00105: val_loss improved from 0.24655 to 0.24248, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8676 - val_loss: 0.2425 - val_accuracy: 0.9176\n",
      "Epoch 106/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2051 - accuracy: 0.9375\n",
      "Epoch 00106: val_loss did not improve from 0.24248\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8511 - val_loss: 0.2538 - val_accuracy: 0.8901\n",
      "Epoch 107/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2059 - accuracy: 0.8750\n",
      "Epoch 00107: val_loss did not improve from 0.24248\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8582 - val_loss: 0.2621 - val_accuracy: 0.9121\n",
      "Epoch 108/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3285 - accuracy: 0.9062\n",
      "Epoch 00108: val_loss did not improve from 0.24248\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8511 - val_loss: 0.2514 - val_accuracy: 0.9176\n",
      "Epoch 109/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4554 - accuracy: 0.7812\n",
      "Epoch 00109: val_loss did not improve from 0.24248\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8440 - val_loss: 0.2591 - val_accuracy: 0.9066\n",
      "Epoch 110/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3113 - accuracy: 0.8438\n",
      "Epoch 00110: val_loss improved from 0.24248 to 0.23177, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8511 - val_loss: 0.2318 - val_accuracy: 0.9176\n",
      "Epoch 111/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8125\n",
      "Epoch 00111: val_loss did not improve from 0.23177\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8889 - val_loss: 0.2477 - val_accuracy: 0.8736\n",
      "Epoch 112/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2434 - accuracy: 0.8750\n",
      "Epoch 00112: val_loss improved from 0.23177 to 0.22802, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.8629 - val_loss: 0.2280 - val_accuracy: 0.9121\n",
      "Epoch 113/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2324 - accuracy: 0.8750\n",
      "Epoch 00113: val_loss improved from 0.22802 to 0.20797, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.9054 - val_loss: 0.2080 - val_accuracy: 0.9231\n",
      "Epoch 114/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2335 - accuracy: 0.8750\n",
      "Epoch 00114: val_loss did not improve from 0.20797\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8652 - val_loss: 0.2436 - val_accuracy: 0.8681\n",
      "Epoch 115/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2105 - accuracy: 0.9062\n",
      "Epoch 00115: val_loss did not improve from 0.20797\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8629 - val_loss: 0.2423 - val_accuracy: 0.8791\n",
      "Epoch 116/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4762 - accuracy: 0.6875\n",
      "Epoch 00116: val_loss improved from 0.20797 to 0.20696, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2845 - accuracy: 0.8771 - val_loss: 0.2070 - val_accuracy: 0.9341\n",
      "Epoch 117/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2465 - accuracy: 0.8438\n",
      "Epoch 00117: val_loss did not improve from 0.20696\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8794 - val_loss: 0.2395 - val_accuracy: 0.8681\n",
      "Epoch 118/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2064 - accuracy: 0.9062\n",
      "Epoch 00118: val_loss improved from 0.20696 to 0.19215, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2950 - accuracy: 0.8700 - val_loss: 0.1921 - val_accuracy: 0.9451\n",
      "Epoch 119/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2898 - accuracy: 0.9062\n",
      "Epoch 00119: val_loss improved from 0.19215 to 0.18410, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2822 - accuracy: 0.8818 - val_loss: 0.1841 - val_accuracy: 0.9505\n",
      "Epoch 120/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3043 - accuracy: 0.8750\n",
      "Epoch 00120: val_loss did not improve from 0.18410\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8605 - val_loss: 0.2318 - val_accuracy: 0.9011\n",
      "Epoch 121/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2776 - accuracy: 0.9062\n",
      "Epoch 00121: val_loss did not improve from 0.18410\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8723 - val_loss: 0.2268 - val_accuracy: 0.8901\n",
      "Epoch 122/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.3650 - accuracy: 0.8438\n",
      "Epoch 00122: val_loss did not improve from 0.18410\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8676 - val_loss: 0.2222 - val_accuracy: 0.9286\n",
      "Epoch 123/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9688\n",
      "Epoch 00123: val_loss did not improve from 0.18410\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8652 - val_loss: 0.2401 - val_accuracy: 0.8846\n",
      "Epoch 124/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2792 - accuracy: 0.8750\n",
      "Epoch 00124: val_loss did not improve from 0.18410\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8889 - val_loss: 0.1923 - val_accuracy: 0.9451\n",
      "Epoch 125/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2930 - accuracy: 0.9062\n",
      "Epoch 00125: val_loss improved from 0.18410 to 0.18206, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.8889 - val_loss: 0.1821 - val_accuracy: 0.9451\n",
      "Epoch 126/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2963 - accuracy: 0.8438\n",
      "Epoch 00126: val_loss did not improve from 0.18206\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.8865 - val_loss: 0.1997 - val_accuracy: 0.9121\n",
      "Epoch 127/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4562 - accuracy: 0.8438\n",
      "Epoch 00127: val_loss did not improve from 0.18206\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.9102 - val_loss: 0.1831 - val_accuracy: 0.9505\n",
      "Epoch 128/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.4199 - accuracy: 0.8438\n",
      "Epoch 00128: val_loss improved from 0.18206 to 0.18034, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2374 - accuracy: 0.8913 - val_loss: 0.1803 - val_accuracy: 0.9341\n",
      "Epoch 129/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2931 - accuracy: 0.8750\n",
      "Epoch 00129: val_loss improved from 0.18034 to 0.17886, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2151 - accuracy: 0.9054 - val_loss: 0.1789 - val_accuracy: 0.9231\n",
      "Epoch 130/130\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.2132 - accuracy: 0.8750\n",
      "Epoch 00130: val_loss improved from 0.17886 to 0.15993, saving model to saved_models\\weights.best.basic_mlp.h5\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2065 - accuracy: 0.9125 - val_loss: 0.1599 - val_accuracy: 0.9505\n",
      "Training completed in time:  0:00:08.880358\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 130\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.h5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model \n",
    "\n",
    "Here we will review the accuracy of the model on both the training and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/mlp_ka_sapna\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_models/mlp_ka_sapna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/mlp_ka_sapna\\assets\n",
      "Training Accuracy:  0.9550827145576477\n",
      "Testing Accuracy:  0.9505494236946106\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "model.save('saved_models/mlp_ka_sapna')\n",
    "\n",
    "training_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", training_accuracy[1])\n",
    "\n",
    "testing_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Testing Accuracy: \", testing_accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial Training and Testing accuracy scores are quite high. As there is not a great difference between the Training and Test scores (~5%) this suggests that the model has not suffered from overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_vector = model.predict(x_test)\n",
    "predict_x=model.predict(x_test) \n",
    "predicted_vector=np.argmax(predict_x,axis=1)\n",
    "le = LabelEncoder()\n",
    "yy_pred = to_categorical(le.fit_transform(predicted_vector)) \n",
    "# print(yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.98 0.02]\n",
      " [0.12 0.88]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    np.set_printoptions(precision=2)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "cnf_matrix=confusion_matrix(y_test.argmax(axis=1),yy_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, ['negative','positive'],\n",
    "                      'Confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       127\n",
      "           1       0.88      0.96      0.92        55\n",
      "\n",
      "    accuracy                           0.95       182\n",
      "   macro avg       0.93      0.95      0.94       182\n",
      "weighted avg       0.95      0.95      0.95       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yy_pred.argmax(axis=1),y_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fe9f3c85e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    " \n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "#\n",
    "# Plot the model accuracy vs Epochs\n",
    "#\n",
    "ax[0].plot(epochs, accuracy, 'ro', label='Training accuracy')\n",
    "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[0].legend()\n",
    "#\n",
    "# Plot the loss vs Epochs\n",
    "#\n",
    "ax[1].plot(epochs, loss_values, 'ro', label='Training loss')\n",
    "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Loss', fontsize=16)\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions  \n",
    "\n",
    "Here we will build a method which will allow us to test the models predictions on a specified audio .wav file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    #predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predict_x=model.predict(prediction_feature) \n",
    "    predicted_vector=np.argmax(predict_x,axis=1)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation \n",
    "\n",
    "#### Test with sample data \n",
    "\n",
    "Initial sainity check to verify the predictions using a subsection of the sample audio files we explored in the first notebook. We expect the bulk of these to be classified correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.99303036928176879882812500000000\n",
      "1 \t\t :  0.00696968426927924156188964843750\n"
     ]
    }
   ],
   "source": [
    "# Class: neg\n",
    "\n",
    "filename = './clinical/converted/neg/neg-0421-088-cough-f-66.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 1 \n",
      "\n",
      "0 \t\t :  0.00875048246234655380249023437500\n",
      "1 \t\t :  0.99124956130981445312500000000000\n"
     ]
    }
   ],
   "source": [
    "# Class: positive\n",
    "\n",
    "filename = './clinical/converted/pos/pos-0421-094-cough-m-51.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Class: Street music \n",
    "\n",
    "# filename = '../UrbanSound Dataset sample/audio/101848-9-0-0.wav'\n",
    "# print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Class: Car Horn \n",
    "\n",
    "# filename = '../UrbanSound Dataset sample/audio/100648-1-0-0.wav'\n",
    "# print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "From this brief sanity check the model seems to predict well. One errror was observed whereby a car horn was incorrectly classifed as a dog bark. \n",
    "\n",
    "We can see from the per class confidence that this was quite a low score (43%). This allows follows our early observation that a dog bark and car horn are similar in spectral shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other audio\n",
    "\n",
    "Here we will use a sample of various copyright free sounds that we not part of either our test or training data to further validate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '../Evaluation audio/pos/az5zELVN7ObicxGrBLMoX8ki1LF2_shallow_1.wav'\n",
    "#print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.90905565023422241210937500000000\n",
      "1 \t\t :  0.09094434231519699096679687500000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Tanya(20-4-2021).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '../Evaluation audio/pos/Fi2lLmV3LHR5brvXs0z1JSKDvnI2_heavy_1.wav'\n",
    "\n",
    "#print_prediction(filename) \n",
    "\n",
    "# sample data weighted towards gun shot - peak in the dog barking sample is simmilar in shape to the gun shot sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '../Evaluation audio/neg/0zAgZhOXaGhmL1SnhkzJOIoowKg2_heavy_1.wav'\n",
    "\n",
    "#print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.92866593599319458007812500000000\n",
      "1 \t\t :  0.07133407145738601684570312500000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Ghaziabad.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.82455629110336303710937500000000\n",
      "1 \t\t :  0.17544366419315338134765625000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/coughtest2.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#filename = '../Evaluation audio/neg/zBiORuLmvGhOciaUXFeAKRhMyhj2_heavy_5.wav'\n",
    "\n",
    "#print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 1 \n",
      "\n",
      "0 \t\t :  0.12461473792791366577148437500000\n",
      "1 \t\t :  0.87538528442382812500000000000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Divyam.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.82465344667434692382812500000000\n",
      "1 \t\t :  0.17534659802913665771484375000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/DJ(03-05-21).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.85730642080307006835937500000000\n",
      "1 \t\t :  0.14269351959228515625000000000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/DJ2.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 1 \n",
      "\n",
      "0 \t\t :  0.14283017814159393310546875000000\n",
      "1 \t\t :  0.85716974735260009765625000000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/DJ3.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.99734133481979370117187500000000\n",
      "1 \t\t :  0.00265863956883549690246582031250\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Vardhika(03-05-21).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 1 \n",
      "\n",
      "0 \t\t :  0.19803266227245330810546875000000\n",
      "1 \t\t :  0.80196732282638549804687500000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Tanyas_Grandma(29-4-2021).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.77881205081939697265625000000000\n",
      "1 \t\t :  0.22118791937828063964843750000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Mom(29-4-2021).wav'\n",
    "\n",
    "print_prediction(filename) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.85706651210784912109375000000000\n",
      "1 \t\t :  0.14293350279331207275390625000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Avi(29-4-2021).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.88225281238555908203125000000000\n",
      "1 \t\t :  0.11774717271327972412109375000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Bhaiya(04-05-21).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 1 \n",
      "\n",
      "0 \t\t :  0.46860334277153015136718750000000\n",
      "1 \t\t :  0.53139662742614746093750000000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Papa(29-4-2021).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.90370321273803710937500000000000\n",
      "1 \t\t :  0.09629682451486587524414062500000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Shreya2(08-05-21).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0 \n",
      "\n",
      "0 \t\t :  0.67805248498916625976562500000000\n",
      "1 \t\t :  0.32194754481315612792968750000000\n"
     ]
    }
   ],
   "source": [
    "filename = '../Evaluation audio/Satyashree3(08-05-21).wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "The performance of our initial model is satisfactorry and has generalised well, seeming to predict well when tested against new audio data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *In the next notebook we will refine our model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
